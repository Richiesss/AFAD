experiment:
  name: "AFAD_MNIST_Phase1"
  seed: 42
  num_rounds: 20

server:
  address: "0.0.0.0:8080"
  min_clients: 5
  min_fit_clients: 5

strategy:
  type: "AFAD"
  intra_family: "heterofl"      # 同族内集約方式
  inter_family: "fedgen"        # 異種間集約方式
  generator:
    noise_dim: 32
    hidden_dim: 256
  fedgen:
    gen_lr: 0.0003              # Generator 学習率 (Adam)
    batch_size: 128             # Generator 学習バッチサイズ
    ensemble_alpha: 1.0         # Server: Teacher Loss 重み
    ensemble_eta: 1.0           # Server: Diversity Loss 重み
    gen_epochs: 2               # Generator 学習エポック数/ラウンド
    teacher_iters: 25           # Teacher イテレーション数/エポック
    # Server-side knowledge distillation (replaces client-side regularization)
    temperature: 4.0            # KD temperature (higher = softer labels)
    distill_lr: 0.0001          # Distillation learning rate (Adam, conservative)
    distill_epochs: 1           # Distillation epochs per round
    distill_steps: 5            # Gradient steps per epoch (conservative)
    distill_alpha: 1.0          # KD loss weight (1.0 = KD only, no hard label CE)
    distill_beta: 0.1           # EMA blending: (1-β)*original + β*distilled
    distill_every: 2            # Distill every N rounds after warmup

clients:
  - id: "client_0"
    model: "resnet50"
    device: "cuda:0"
    host: "server"              # Ubuntu machine
  - id: "client_1"
    model: "mobilenetv3_large"
    device: "cuda:0"
    host: "server"
  - id: "client_2"
    model: "resnet18"
    device: "cuda:0"
    host: "wsl2"                # WSL2 machine
  - id: "client_3"
    model: "vit_tiny"
    device: "cuda:0"
    host: "wsl2"
  - id: "client_4"
    model: "deit_small"
    device: "cuda:0"
    host: "wsl2"

data:
  dataset: "mnist"              # Phase1: mnist, Phase2: medmnist
  num_classes: 10
  distribution: "iid"           # iid | non_iid
  batch_size: 64

training:
  local_epochs: 2
  learning_rate: 0.01
  optimizer: "sgd"
  momentum: 0.9
  weight_decay: 0.0001

evaluation:
  metrics: ["accuracy", "f1_score", "communication_cost"]
  eval_every: 1                 # ラウンド毎に評価
